#Lecture Notes

These are the lecture notes covering some elements of statistical learning, generalized linear regression, logistic regression, artificial neural networks and convolutional neural networks.
The table of contents is reproduced here:

1. References
2. Learning from Data
3. Regression via Generalized Linear Models
    1. Linear Regression 
    2. Bias and Variance
    3. Regularization
4. Optimization
    1. Gradient Descent
    2. Stochastic Gradient Descent 
    3. Gradient Flows
5. Classification via Logistic Regression
    1. Binary Classification 
    2. Multinary Classification 
6. Neural Networks
    1. The Perceptron 
    2. Artificial Neural Networks
    3. How Neural Networks Learn: Backpropagation
    4. Vectorized Backpropagation 
7. Training a Neural Network
    1. The Vanishing Gradients Problem: Initialization, Activation Functions
    2. Zero Centering Activations 
    3. Batch Normalization 
    4. Choosing the Learning Rate
8. Convolutional Neural Networks
    1. A Simple Edge Detection Problem 
    2. Convolutional Layers 
    3. Pooling Layers 
    4. Putting it all together: A basic ConvNet
    5. A Network within a Network
    6. Convolutions are All You Need

We have also included as appendices:
1. Bias/Variance Decomposition
2. A Bayesian Treatment of Regression
3. Entropy and Cross-Entropy from Information Theory
